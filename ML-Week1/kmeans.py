# -*- coding: utf-8 -*-
"""kmeans.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MEm4NSmX67UHyDzmpi5treyGJ1jVIkMy
"""

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import pickle

"""# task 1 , 2 , 3 (load)"""

with open('tfidf_train_vectors_with_labels.pickle', 'rb') as f:
    tfidf_train_vectors, train_labels = pickle.load(f)

with open('tfidf_val_vectors_with_labels.pickle', 'rb') as f:
    tfidf_val_vectors, val_labels = pickle.load(f)

"""# Task 4"""

from sklearn.metrics import make_scorer

train_labels = train_labels.values.flatten()
val_labels  = val_labels.values.flatten()

def custom_scorer(y_true, y_pred):
    # Your custom scoring logic
    # Example: Return the sum of correct predictions
    accuracy = sum(y_true == y_pred)
    accuracy_2 = sum(y_true == [1 if 0 else 1 for val in y_pred])
    acc = max(accuracy, accuracy_2)
    return acc / y_true.shape[0]

# Create a scorer using make_scorer
custom_score = make_scorer(custom_scorer)

from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

# Assuming tfidf_train_vectors is your TF-IDF vectors for training
kmeans_model = KMeans(n_clusters=2, random_state=30)  # Example: 8 clusters
kmeans_model.fit(tfidf_train_vectors)

# Predictions on validation and test datasets (not applicable for clustering)
val_predictions_kmeans = kmeans_model.predict(tfidf_val_vectors)
# print(test_predictions_kmeans)

# Evaluation using silhouette score
silhouette_val = silhouette_score(tfidf_val_vectors, val_predictions_kmeans)
val_acc = custom_scorer(val_labels, val_predictions_kmeans)
print("Silhouette Score (Validation) for KMeans:", silhouette_val)
print("Accuracy Score (Validation) for KMeans:", val_acc)

val_predictions_kmeans.shape

# Assuming tfidf_train_vectors is your TF-IDF vectors for training
parameters_kmeans = {
    'n_clusters': [2],  # Number of clusters
    'init': ['k-means++', 'random'],  # Method for initialization
    'algorithm': ['lloyd', 'elkan'],  # K-means algorithm to use
    'n_init': [10, 20, 30],
}

kmeans_model = KMeans()

grid_search_kmeans = GridSearchCV(kmeans_model, parameters_kmeans, cv=5, scoring= custom_score)  # Use an appropriate scoring metric
grid_search_kmeans.fit(tfidf_train_vectors, train_labels)  # Fit GridSearchCV to the training data

# Get the best hyperparameters
best_hyperparameters_kmeans = grid_search_kmeans.best_params_
best_model = grid_search_kmeans.best_estimator_  # Get the best model

# Compute silhouette score manually
best_predictions_kmeans = best_model.predict(tfidf_train_vectors)
silhouette_train = silhouette_score(tfidf_train_vectors, best_predictions_kmeans)

print("Best Hyperparameters (KMeans):", best_hyperparameters_kmeans)
print("Silhouette Score (Train) for KMeans:", silhouette_train)

val_predictions_kmeans = best_model.predict(tfidf_val_vectors)
# Evaluation
val_accuracy_kmeans = custom_scorer(val_labels, val_predictions_kmeans)
print("Validation Accuracy for KMeans::", val_accuracy_kmeans)

# save model
filename = "kmean_model.pickle"
pickle.dump(best_model, open(filename, "wb"))