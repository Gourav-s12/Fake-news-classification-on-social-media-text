{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgoJ2JisGLF6",
        "outputId": "365308d9-934b-4802-b74d-34ed01031704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.13.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.28)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.10.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext) (2.11.1)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC,LinearSVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "! pip install optuna\n",
        "import optuna\n",
        "!pip install fasttext\n",
        "import fasttext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSJJqKE0Hr8N"
      },
      "source": [
        "# task 1 , 2 , 3 (load)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "4LWOSwYDH5ul"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('train_split.csv')\n",
        "val_data = pd.read_csv('val_split.csv')\n",
        "# test_data = pd.read_csv('test_split.csv')\n",
        "\n",
        "train_labels = train_data['label']\n",
        "val_labels = val_data['label']\n",
        "# test_labels = test_data['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "arNsJnvixGtU"
      },
      "outputs": [],
      "source": [
        "# Combine train and validation data for fasttext training\n",
        "combined_data = pd.concat([train_data, val_data])\n",
        "\n",
        "# Combine train and validation sentences for fasttext training\n",
        "combined_data_df = pd.concat([train_data, val_data], axis=0)\n",
        "max_inp_len = max(combined_data_df['tweet'].apply(lambda x: len(x.split(\" \"))))\n",
        "combined_labels = combined_data_df['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "RSc3vA7fxGvx"
      },
      "outputs": [],
      "source": [
        "combined_data_df[[\"tweet\"]].to_csv('combined_data.txt', header=False, index=False,  encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "9bQQ6CraxGyQ"
      },
      "outputs": [],
      "source": [
        "# Specify the path for the fasttext model\n",
        "fasttext_model_path = 'fasttext_model.bin'\n",
        "\n",
        "# Train the FastText model on the combined dataset\n",
        "model = fasttext.train_unsupervised('combined_data.txt', model='skipgram')\n",
        "model.save_model(fasttext_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_gXC6x3G46X",
        "outputId": "a404cf8e-c93b-456e-bc5f-6a143a359493"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ],
      "source": [
        "# Specify the path for the fasttext model\n",
        "fasttext_model_path = 'fasttext_model.bin'\n",
        "\n",
        "fasttext_model = fasttext.load_model(fasttext_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "1h70GEC2KvQt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_embedding_matrix(sentences, model, max_inp_len):\n",
        "    embedding_matrix = np.zeros((len(sentences), max_inp_len, model.get_dimension()))\n",
        "\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        tokens = sentence.split()[:max_inp_len]\n",
        "        for j, token in enumerate(tokens):\n",
        "            embedding_matrix[i, j, :] = model.get_word_vector(token)\n",
        "\n",
        "    print(embedding_matrix.shape)\n",
        "    return embedding_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOVfyC8dLI4s",
        "outputId": "ce182a72-4725-4430-ea74-22c1c188ee2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "970 100\n"
          ]
        }
      ],
      "source": [
        "max_inp_len = max(pd.concat([train_data, val_data], axis=0)['tweet'].apply(lambda x: len(x.split(\" \"))))\n",
        "d = fasttext_model.get_dimension()\n",
        "print(max_inp_len , d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGUF6MWxJeau",
        "outputId": "b5e4587a-cdfd-40d0-e77d-6e93674f1de4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8480, 970, 100)\n",
            "(1060, 970, 100)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Create embedding matrices for train, val, and test datasets\n",
        "train_embedding_matrix = create_embedding_matrix(train_data['tweet'], fasttext_model, max_inp_len)\n",
        "val_embedding_matrix = create_embedding_matrix(val_data['tweet'], fasttext_model, max_inp_len)\n",
        "# test_embedding_matrix = create_embedding_matrix(test_data['tweet'], fasttext_model, max_inp_len)\n",
        "# train_val_embedding_matrix = create_embedding_matrix(combined_data_df['tweet'], fasttext_model, max_inp_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGk_iH1SkD2j",
        "outputId": "30c507c4-98f5-4c3c-e66f-08a049b43be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8480,) (8480, 970, 100)\n"
          ]
        }
      ],
      "source": [
        "print(train_labels.shape , train_embedding_matrix.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa4nt3ALHnkV"
      },
      "source": [
        "# Task 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "xO71sCcof_bL"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        # Convert sparse matrix to dense tensor\n",
        "        self.x = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(Y, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Add an extra dimension to represent channels (1 in this case)\n",
        "        x_sample = self.x[idx]   # .unsqueeze(0)\n",
        "        return x_sample, self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "fYtWeSVUgVBW"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(train_embedding_matrix, train_labels)\n",
        "eval_dataset = CustomDataset(val_embedding_matrix, val_labels)\n",
        "# test_dataset = CustomDataset(test_embedding_matrix, test_labels)\n",
        "# train_val_dataset = CustomDataset(train_val_embedding_matrix, combined_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "6tVeq41whaz0"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle = True)\n",
        "eval_dataloader = DataLoader(eval_dataset, batch_size = 32, shuffle = False)\n",
        "# test_dataloader = DataLoader(test_dataset, batch_size = 32, shuffle = False)\n",
        "# train_dataloader = DataLoader(train_val_dataset, batch_size = 32, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKm4VxFvhdYJ",
        "outputId": "9238ef6c-e210-4d50-b522-606915579783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 970, 100]) torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "for x, y in train_dataloader:\n",
        "    print(x.shape, y.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "Wijkk9mUX4kQ"
      },
      "outputs": [],
      "source": [
        "# train_loader = torch.utils.data.DataLoader(train_dataset,          # our raw data\n",
        "#                                            batch_size=32,  # the size of batches we want the dataloader to return\n",
        "#                                            shuffle=True,           # shuffle our data before batching\n",
        "#                                            drop_last=False)        # don't drop the last batch even if it's smaller than batch_size\n",
        "# imgs, targets = next(iter(train_loader))\n",
        "# imgs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_sv7-09hpph"
      },
      "source": [
        "## Basic Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "O7aNAiWbhsx7",
        "outputId": "69caf121-a680-416f-ef5f-383a8ab7a273"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 123
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "YJNXYbCRhwJy"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ConvolutionalNeuralNetwork0(nn.Module):\n",
        "    def __init__(self, d, num_classes=2):\n",
        "        super(ConvolutionalNeuralNetwork0, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=d, out_channels=128, kernel_size=5)\n",
        "        self.bn1 = nn.BatchNorm1d(128)\n",
        "        self.conv2 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.conv3 = nn.Conv1d(in_channels=256, out_channels=256, kernel_size=3)\n",
        "        self.bn3 = nn.BatchNorm1d(256)\n",
        "\n",
        "        self.fc1 = nn.Linear(256 * 119, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "5AM2oZ_-iuvW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "network = ConvolutionalNeuralNetwork0(d).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek5Vekjoiu0C",
        "outputId": "aa8aaae5-0e86-4295-e89f-f6ea3b3f618b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv1d-1             [-1, 128, 966]          64,128\n",
            "       BatchNorm1d-2             [-1, 128, 966]             256\n",
            "              ReLU-3             [-1, 128, 966]               0\n",
            "         MaxPool1d-4             [-1, 128, 483]               0\n",
            "            Conv1d-5             [-1, 256, 481]          98,560\n",
            "       BatchNorm1d-6             [-1, 256, 481]             512\n",
            "              ReLU-7             [-1, 256, 481]               0\n",
            "         MaxPool1d-8             [-1, 256, 240]               0\n",
            "            Conv1d-9             [-1, 256, 238]         196,864\n",
            "      BatchNorm1d-10             [-1, 256, 238]             512\n",
            "             ReLU-11             [-1, 256, 238]               0\n",
            "        MaxPool1d-12             [-1, 256, 119]               0\n",
            "           Linear-13                  [-1, 128]       3,899,520\n",
            "             ReLU-14                  [-1, 128]               0\n",
            "           Linear-15                    [-1, 2]             258\n",
            "================================================================\n",
            "Total params: 4,260,610\n",
            "Trainable params: 4,260,610\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.37\n",
            "Forward/backward pass size (MB): 8.22\n",
            "Params size (MB): 16.25\n",
            "Estimated Total Size (MB): 24.84\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "# Assuming your input data size is (970, 100)\n",
        "input_size = (100, 970)  # (channels, width)\n",
        "\n",
        "# Print the model summary\n",
        "summary(network, input_size=input_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4sPuiZliu3A",
        "outputId": "6d6fd945-d88e-41ed-a5cb-206e62f886e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 970, 100]) torch.Size([32, 100, 970]) torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "batch_x, batch_y = next(iter(train_dataloader))\n",
        "print(batch_x.shape, batch_x.permute(0, 2, 1).shape, batch_y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF8b0Gili60M"
      },
      "source": [
        "## Basic Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "o6caXoVbiu5u"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optim = torch.optim.Adam(network.parameters(), lr = 0.001)\n",
        "epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "6509b7hPiu7z"
      },
      "outputs": [],
      "source": [
        "train_epoch_loss = []\n",
        "eval_epoch_loss = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQT1UUZyiu-b",
        "outputId": "c605527d-35af-405e-b381-12aa9cf9ca8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 2/10 [00:14<00:56,  7.05s/it]"
          ]
        }
      ],
      "source": [
        "for epoch in tqdm(range(epochs)):\n",
        "    curr_loss = 0\n",
        "    total = 0\n",
        "    for train_x, train_y in train_dataloader:\n",
        "\n",
        "        train_x = train_x.to(device)\n",
        "        train_y = train_y.to(device)\n",
        "        optim.zero_grad()\n",
        "\n",
        "        y_pred = network(train_x.permute(0, 2, 1))\n",
        "        loss = criterion(y_pred, train_y)\n",
        "\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        curr_loss += loss.item()\n",
        "        total += len(train_y)\n",
        "    train_epoch_loss.append(curr_loss / total)\n",
        "\n",
        "    curr_loss = 0\n",
        "    total = 0\n",
        "    for eval_x, eval_y in eval_dataloader:\n",
        "        eval_x = eval_x.to(device)\n",
        "        eval_y = eval_y.to(device)\n",
        "        optim.zero_grad()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            y_pred = network(eval_x.permute(0, 2, 1))\n",
        "\n",
        "        loss = criterion(y_pred, eval_y)\n",
        "\n",
        "        curr_loss += loss.item()\n",
        "        total += len(train_y)\n",
        "    eval_epoch_loss.append(curr_loss / total)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4N58Lo0uivA1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(epochs), train_epoch_loss, label='train')\n",
        "plt.plot(range(epochs), eval_epoch_loss, label='eval')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--jMTpLXivDJ"
      },
      "outputs": [],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for x, y in eval_dataloader:\n",
        "    x = x.to(device)\n",
        "    with torch.no_grad():\n",
        "        yp = network(x.permute(0, 2, 1))\n",
        "    yp = torch.argmax(yp.cpu(), dim = 1)\n",
        "    correct += (yp == y).sum()\n",
        "    total += len(y)\n",
        "prev_eval_acc = correct / total\n",
        "print(f\"Accuracy on Eval Data {(prev_eval_acc * 100):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lv9R8U6BlwfF"
      },
      "outputs": [],
      "source": [
        "prev_model = network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKp3Kcxhn86w"
      },
      "source": [
        "## now hyperparameter optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kxYyFtPnkqt",
        "outputId": "bf16a08d-610e-499e-d084-d5b952ac19a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.3.1-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.4/840.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.10.1 torchmetrics-1.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics\n",
        "from torchmetrics import Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Jktq4harhwMp"
      },
      "outputs": [],
      "source": [
        "import torch.nn.init as init  # Import the init module from PyTorch\n",
        "\n",
        "class ConvolutionalNeuralNetwork2(nn.Module):\n",
        "    def __init__(self, input_dim, d, output_dim, n_layers, n_units, dropout_prob, activation, optimizer_name,weight_init_method, learning_rate, cnn_kernel, cnn_stride, cnn_padding, cnn_channel):\n",
        "        super(ConvolutionalNeuralNetwork2, self).__init__()\n",
        "        layers = []\n",
        "\n",
        "        # self.conv1 = nn.Conv1d(in_channels=d, out_channels=128, kernel_size=5)\n",
        "        # self.conv2 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3)\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=d, out_channels=cnn_channel, kernel_size=cnn_kernel, stride=cnn_stride, padding=cnn_padding)\n",
        "        input_dim = self.calculate_conv_output_size(input_dim, cnn_kernel, cnn_stride, cnn_padding)\n",
        "        input_dim = self.calculate_pool_output_size(input_dim, 2)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(in_channels=cnn_channel, out_channels=cnn_channel, kernel_size=cnn_kernel, stride=cnn_stride, padding=cnn_padding)\n",
        "        input_dim = self.calculate_conv_output_size(input_dim, cnn_kernel, cnn_stride, cnn_padding)\n",
        "        input_dim = self.calculate_pool_output_size(input_dim, 2)\n",
        "\n",
        "        self.fc1 = nn.Linear(cnn_channel * input_dim, 128)\n",
        "\n",
        "        self.activation = activation\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "        self.bn = nn.BatchNorm1d(cnn_channel)\n",
        "\n",
        "        in_features = 128\n",
        "        for i in range(n_layers):\n",
        "            layers.append(nn.Linear(in_features, n_units))\n",
        "            layers.append(activation)\n",
        "            layers.append(nn.Dropout(dropout_prob))\n",
        "            in_features = n_units\n",
        "        layers.append(nn.Linear(in_features, output_dim))\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "        # Initialize optimizer and learning rate scheduler\n",
        "        self.optimizer_name = optimizer_name\n",
        "        self.optimizer = self._get_optimizer(optimizer_name, learning_rate)\n",
        "        # self.apply_weight_init(weight_init_method)\n",
        "\n",
        "    def _get_optimizer(self, optimizer_name, learning_rate):\n",
        "        if optimizer_name == 'Adam':\n",
        "            return torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
        "        elif optimizer_name == 'SGD':\n",
        "            return torch.optim.SGD(self.parameters(), lr=learning_rate, momentum=0.9)\n",
        "        elif optimizer_name == 'RMSprop':\n",
        "            return torch.optim.RMSprop(self.parameters(), lr=learning_rate)\n",
        "        else:\n",
        "            raise ValueError(f'Invalid optimizer name: {optimizer_name}')\n",
        "\n",
        "    def apply_weight_init(self, weight_init_method):\n",
        "        if weight_init_method == 'uniform':\n",
        "            init_func = init.uniform_\n",
        "        elif weight_init_method == 'normal':\n",
        "            init_func = init.normal_\n",
        "        elif weight_init_method == 'xavier':\n",
        "            init_func = init.xavier_uniform_\n",
        "        else:\n",
        "            raise ValueError(f'Invalid weight initialization method: {weight_init_method}')\n",
        "        # Apply weight initialization to each linear layer\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.Linear):\n",
        "                init_func(module.weight)\n",
        "                if module.bias is not None:\n",
        "                    init.constant_(module.bias, 0)\n",
        "\n",
        "    def calculate_conv_output_size(self, input_size, kernel_size, stride, padding):\n",
        "        return int(((input_size - kernel_size + 2 * padding) / stride) + 1)\n",
        "\n",
        "    def calculate_pool_output_size(self, input_size, pool_size):\n",
        "        return int((input_size  / pool_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # Flatten the output before the fully connected layers\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "TvTUktp6mDGT"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, dataloader, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for inputs, targets in dataloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs.permute(0, 2, 1))\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        y_pred = torch.argmax(outputs, dim = 1)\n",
        "        correct_predictions += (y_pred == targets).sum().item()\n",
        "        total_samples += len(targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    accuracy = correct_predictions / total_samples\n",
        "    total_loss /= total_samples\n",
        "    return total_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "MYqgsJqBWfmT"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(network, criterion, eval_dataloader, device):\n",
        "    network.eval()\n",
        "\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for eval_x, eval_y in eval_dataloader:\n",
        "            eval_x = eval_x.to(device)\n",
        "            eval_y = eval_y.to(device)\n",
        "\n",
        "            y_pred = network(eval_x.permute(0, 2, 1))\n",
        "            loss = criterion(y_pred, eval_y)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            y_pred = torch.argmax(y_pred, dim = 1)\n",
        "            correct_predictions += (y_pred == eval_y).sum().item()\n",
        "            total_samples += len(eval_y)\n",
        "\n",
        "    total_loss /= total_samples\n",
        "    accuracy = correct_predictions / total_samples\n",
        "\n",
        "    return total_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "2tbC4F1me8WC"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from torch.optim.lr_scheduler import StepLR, ExponentialLR\n",
        "from torch.nn.init import xavier_uniform_, kaiming_normal_\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.optim.lr_scheduler import StepLR, ExponentialLR\n",
        "from torch.nn import LeakyReLU, PReLU\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import L1Loss, MSELoss\n",
        "\n",
        "def objective(trial):\n",
        "    # Define hyperparameters to be optimized\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
        "    n_layers = trial.suggest_int(\"n_layers\", 1, 2)\n",
        "    n_units = trial.suggest_int(\"n_units\", 16, 128)\n",
        "    dropout_prob = trial.suggest_float(\"dropout_prob\", 0.0, 0.5)\n",
        "    activation = trial.suggest_categorical(\"activation\", [\"ReLU\", \"LeakyReLU\", \"PReLU\"])\n",
        "    weight_init_method = trial.suggest_categorical(\"weight_init_method\", [\"uniform\", \"normal\", \"xavier\"])\n",
        "    optimizer_choice = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\", \"RMSprop\"])\n",
        "    # lr_schedule = trial.suggest_categorical(\"lr_schedule\", [\"step_lr\", \"exp_lr\"])\n",
        "    use_early_stopping = trial.suggest_categorical(\"use_early_stopping\", [True, False])\n",
        "    patience = trial.suggest_int(\"patience\", 5, 10)\n",
        "    # gradient_accumulation_steps = trial.suggest_int(\"gradient_accumulation_steps\", 1, 5)\n",
        "    # regularization_strength = trial.suggest_float(\"regularization_strength\", 0.0, 0.1)\n",
        "    epochs = trial.suggest_int(\"epochs\", 10, 25)\n",
        "\n",
        "    #for CNN\n",
        "    cnn_kernel = 2 * (trial.suggest_int(\"cnn_kernel\", 1, 3)) + 1  # to get odd number using 2*x+1\n",
        "    max_stride_pad = (cnn_kernel - 1)/2\n",
        "    cnn_stride = trial.suggest_int(\"cnn_stride\", 1, max_stride_pad)\n",
        "    cnn_padding = trial.suggest_categorical(\"cnn_padding\", [0, 3])\n",
        "    cnn_channel = trial.suggest_categorical(\"cnn_channel\", [32, 64, 128])\n",
        "\n",
        "    # Wrap activation functions inside nn.Module subclass\n",
        "    if activation == \"ReLU\":\n",
        "        activation =nn.ReLU()\n",
        "    elif activation == \"LeakyReLU\":\n",
        "        activation =nn.LeakyReLU()\n",
        "    elif activation == \"PReLU\":\n",
        "        activation =nn.PReLU()\n",
        "    else:\n",
        "        raise ValueError(f'Invalid activation method: {activation}')\n",
        "\n",
        "    # Create an instance of your Network\n",
        "    network = ConvolutionalNeuralNetwork2(input_dim = max_inp_len, d = d, output_dim=2, n_layers=n_layers,\n",
        "                            n_units=n_units, dropout_prob=dropout_prob, activation=activation,\n",
        "                            optimizer_name=optimizer_choice,weight_init_method=weight_init_method,\n",
        "                            learning_rate = learning_rate, cnn_kernel = cnn_kernel, cnn_stride = cnn_stride,\n",
        "                            cnn_padding = cnn_padding, cnn_channel = cnn_channel)\n",
        "\n",
        "    optimizer = network.optimizer\n",
        "\n",
        "    # input_size = (100, 970)  # (channels, width)\n",
        "\n",
        "    # # Print the model summary\n",
        "    # summary(network, input_size=input_size)\n",
        "\n",
        "    # Move the model to the appropriate device\n",
        "    network.to(device)\n",
        "    best_eval_loss = float('inf')\n",
        "    no_improvement = 0\n",
        "\n",
        "    # Define DataLoader instances\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    eval_dataloader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False)\n",
        "    # test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
        "        train_loss , train_acc = train_model(network, criterion, optimizer, train_dataloader, device)\n",
        "        eval_loss, eval_acc = evaluate_model(network, criterion, eval_dataloader, device)\n",
        "\n",
        "        # Report the validation loss to Optuna for optimization\n",
        "        trial.report(eval_loss, epoch)\n",
        "\n",
        "        # Handle pruning based on the intermediate value\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "        # Early stopping\n",
        "        if use_early_stopping:\n",
        "            if eval_loss < best_eval_loss:\n",
        "                best_val_loss = eval_loss\n",
        "                no_improvement = 0\n",
        "            else:\n",
        "                no_improvement += 1\n",
        "                if no_improvement >= patience:\n",
        "                    break\n",
        "\n",
        "    print(f\"Training acc = {train_acc} , Val acc = {eval_acc}\")\n",
        "    return eval_acc  # eval_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzSwD7ejzAku",
        "outputId": "77c6b9a2-0c9a-46d3-e88c-12702d47f156"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-12 19:40:27,928] A new study created in memory with name: no-name-e032e0a6-74ab-44fb-96d6-fd4d02607531\n",
            "Epochs: 100%|██████████| 24/24 [01:59<00:00,  4.98s/it]\n",
            "[I 2024-03-12 19:42:27,418] Trial 0 finished with value: 0.8358490566037736 and parameters: {'learning_rate': 3.799285833287359e-05, 'batch_size': 128, 'n_layers': 1, 'n_units': 117, 'dropout_prob': 0.4697903586223736, 'activation': 'PReLU', 'weight_init_method': 'uniform', 'optimizer': 'SGD', 'use_early_stopping': False, 'patience': 7, 'epochs': 24, 'cnn_kernel': 2, 'cnn_stride': 2, 'cnn_padding': 0, 'cnn_channel': 64}. Best is trial 0 with value: 0.8358490566037736.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training acc = 0.8859669811320755 , Val acc = 0.8358490566037736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs: 100%|██████████| 13/13 [01:13<00:00,  5.64s/it]\n",
            "[I 2024-03-12 19:43:40,752] Trial 1 finished with value: 0.6584905660377358 and parameters: {'learning_rate': 0.019923452974566012, 'batch_size': 128, 'n_layers': 2, 'n_units': 117, 'dropout_prob': 0.15538194197316796, 'activation': 'ReLU', 'weight_init_method': 'uniform', 'optimizer': 'Adam', 'use_early_stopping': True, 'patience': 7, 'epochs': 13, 'cnn_kernel': 3, 'cnn_stride': 1, 'cnn_padding': 0, 'cnn_channel': 64}. Best is trial 0 with value: 0.8358490566037736.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training acc = 0.9076650943396226 , Val acc = 0.6584905660377358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs: 100%|██████████| 21/21 [01:25<00:00,  4.05s/it]\n",
            "[I 2024-03-12 19:45:05,886] Trial 2 finished with value: 0.5283018867924528 and parameters: {'learning_rate': 6.998724643427357e-05, 'batch_size': 64, 'n_layers': 2, 'n_units': 84, 'dropout_prob': 0.2617735274117893, 'activation': 'LeakyReLU', 'weight_init_method': 'uniform', 'optimizer': 'RMSprop', 'use_early_stopping': True, 'patience': 8, 'epochs': 21, 'cnn_kernel': 3, 'cnn_stride': 1, 'cnn_padding': 0, 'cnn_channel': 128}. Best is trial 0 with value: 0.8358490566037736.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training acc = 0.9966981132075472 , Val acc = 0.5283018867924528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs: 100%|██████████| 13/13 [00:41<00:00,  3.21s/it]\n",
            "[I 2024-03-12 19:45:47,685] Trial 3 finished with value: 0.8783018867924528 and parameters: {'learning_rate': 0.002481580612173, 'batch_size': 64, 'n_layers': 1, 'n_units': 52, 'dropout_prob': 0.10374567505647281, 'activation': 'LeakyReLU', 'weight_init_method': 'xavier', 'optimizer': 'RMSprop', 'use_early_stopping': False, 'patience': 5, 'epochs': 13, 'cnn_kernel': 2, 'cnn_stride': 2, 'cnn_padding': 3, 'cnn_channel': 64}. Best is trial 3 with value: 0.8783018867924528.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training acc = 0.9527122641509433 , Val acc = 0.8783018867924528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs: 100%|██████████| 18/18 [00:51<00:00,  2.88s/it]\n",
            "[I 2024-03-12 19:46:39,579] Trial 4 finished with value: 0.5377358490566038 and parameters: {'learning_rate': 0.006185839385450872, 'batch_size': 32, 'n_layers': 1, 'n_units': 58, 'dropout_prob': 0.25877189679387813, 'activation': 'LeakyReLU', 'weight_init_method': 'uniform', 'optimizer': 'RMSprop', 'use_early_stopping': False, 'patience': 6, 'epochs': 18, 'cnn_kernel': 1, 'cnn_stride': 1, 'cnn_padding': 0, 'cnn_channel': 64}. Best is trial 3 with value: 0.8783018867924528.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training acc = 0.9003537735849056 , Val acc = 0.5377358490566038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:   0%|          | 0/24 [00:03<?, ?it/s]\n",
            "[I 2024-03-12 19:46:43,101] Trial 5 pruned. \n",
            "Epochs:   0%|          | 0/24 [00:02<?, ?it/s]\n",
            "[I 2024-03-12 19:46:45,912] Trial 6 pruned. \n",
            "Epochs: 100%|██████████| 23/23 [01:34<00:00,  4.10s/it]\n",
            "[I 2024-03-12 19:48:20,274] Trial 7 finished with value: 0.5320754716981132 and parameters: {'learning_rate': 1.554019474586251e-05, 'batch_size': 32, 'n_layers': 2, 'n_units': 47, 'dropout_prob': 0.43848775100791176, 'activation': 'ReLU', 'weight_init_method': 'xavier', 'optimizer': 'RMSprop', 'use_early_stopping': True, 'patience': 10, 'epochs': 23, 'cnn_kernel': 2, 'cnn_stride': 1, 'cnn_padding': 3, 'cnn_channel': 128}. Best is trial 3 with value: 0.8783018867924528.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training acc = 0.9806603773584905 , Val acc = 0.5320754716981132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:   5%|▍         | 1/21 [00:05<01:40,  5.01s/it]\n",
            "[I 2024-03-12 19:48:25,308] Trial 8 pruned. \n",
            "Epochs: 100%|██████████| 18/18 [01:10<00:00,  3.90s/it]\n",
            "[I 2024-03-12 19:49:35,514] Trial 9 finished with value: 0.7264150943396226 and parameters: {'learning_rate': 1.7032822198384993e-05, 'batch_size': 32, 'n_layers': 1, 'n_units': 87, 'dropout_prob': 0.03383614793489409, 'activation': 'LeakyReLU', 'weight_init_method': 'normal', 'optimizer': 'Adam', 'use_early_stopping': False, 'patience': 7, 'epochs': 18, 'cnn_kernel': 1, 'cnn_stride': 1, 'cnn_padding': 0, 'cnn_channel': 128}. Best is trial 3 with value: 0.8783018867924528.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training acc = 0.9853773584905661 , Val acc = 0.7264150943396226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:   0%|          | 0/10 [00:02<?, ?it/s]\n",
            "[I 2024-03-12 19:49:38,197] Trial 10 pruned. \n",
            "Epochs:   0%|          | 0/14 [00:04<?, ?it/s]\n",
            "[I 2024-03-12 19:49:42,541] Trial 11 pruned. \n",
            "Epochs:   0%|          | 0/13 [00:04<?, ?it/s]\n",
            "[I 2024-03-12 19:49:47,150] Trial 12 pruned. \n",
            "Epochs:   0%|          | 0/16 [00:04<?, ?it/s]\n",
            "[I 2024-03-12 19:49:51,684] Trial 13 pruned. \n",
            "Epochs:   0%|          | 0/10 [00:02<?, ?it/s]\n",
            "[I 2024-03-12 19:49:54,682] Trial 14 pruned. \n",
            "Epochs:   0%|          | 0/20 [00:02<?, ?it/s]\n",
            "[I 2024-03-12 19:49:57,609] Trial 15 pruned. \n",
            "Epochs:   0%|          | 0/16 [00:03<?, ?it/s]\n",
            "[I 2024-03-12 19:50:01,602] Trial 16 pruned. \n",
            "Epochs:   0%|          | 0/25 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/optuna/pruners/_percentile.py:19: RuntimeWarning: All-NaN slice encountered\n",
            "  return np.nanmax(values)\n",
            "Epochs:   0%|          | 0/25 [00:03<?, ?it/s]\n",
            "[I 2024-03-12 19:50:05,087] Trial 17 pruned. \n",
            "Epochs:   0%|          | 0/15 [00:05<?, ?it/s]\n",
            "[I 2024-03-12 19:50:10,211] Trial 18 pruned. \n",
            "Epochs: 100%|██████████| 12/12 [00:30<00:00,  2.56s/it]\n",
            "[I 2024-03-12 19:50:41,018] Trial 19 finished with value: 0.7094339622641509 and parameters: {'learning_rate': 5.239270614745558e-05, 'batch_size': 32, 'n_layers': 1, 'n_units': 88, 'dropout_prob': 0.20446249841674075, 'activation': 'ReLU', 'weight_init_method': 'normal', 'optimizer': 'Adam', 'use_early_stopping': False, 'patience': 5, 'epochs': 12, 'cnn_kernel': 3, 'cnn_stride': 3, 'cnn_padding': 0, 'cnn_channel': 32}. Best is trial 3 with value: 0.8783018867924528.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training acc = 0.9620283018867924 , Val acc = 0.7094339622641509\n",
            "Best trial:\n",
            "  Value:  0.8783018867924528\n",
            "  Params: \n",
            "    learning_rate: 0.002481580612173\n",
            "    batch_size: 64\n",
            "    n_layers: 1\n",
            "    n_units: 52\n",
            "    dropout_prob: 0.10374567505647281\n",
            "    activation: LeakyReLU\n",
            "    weight_init_method: xavier\n",
            "    optimizer: RMSprop\n",
            "    use_early_stopping: False\n",
            "    patience: 5\n",
            "    epochs: 13\n",
            "    cnn_kernel: 2\n",
            "    cnn_stride: 2\n",
            "    cnn_padding: 3\n",
            "    cnn_channel: 64\n"
          ]
        }
      ],
      "source": [
        "# Create Optuna study and run optimization\n",
        "study = optuna.create_study(direction=\"maximize\")  # or \"minimize\" for a loss\n",
        "study.optimize(objective, n_trials=20, timeout=5000)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "KYGQkwS2qZ5y"
      },
      "outputs": [],
      "source": [
        "train_epoch_loss = []\n",
        "eval_epoch_loss = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "HPl_pp2HmDI3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1376ccf-d92c-44c0-fcc3-f74a9ed0490b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv1d-1              [-1, 64, 486]          32,064\n",
            "       BatchNorm1d-2              [-1, 64, 486]             128\n",
            "         LeakyReLU-3              [-1, 64, 486]               0\n",
            "         LeakyReLU-4              [-1, 64, 486]               0\n",
            "         MaxPool1d-5              [-1, 64, 243]               0\n",
            "            Conv1d-6              [-1, 64, 123]          20,544\n",
            "       BatchNorm1d-7              [-1, 64, 123]             128\n",
            "         LeakyReLU-8              [-1, 64, 123]               0\n",
            "         LeakyReLU-9              [-1, 64, 123]               0\n",
            "        MaxPool1d-10               [-1, 64, 61]               0\n",
            "           Linear-11                  [-1, 128]         499,840\n",
            "           Linear-12                   [-1, 52]           6,708\n",
            "        LeakyReLU-13                   [-1, 52]               0\n",
            "        LeakyReLU-14                   [-1, 52]               0\n",
            "          Dropout-15                   [-1, 52]               0\n",
            "           Linear-16                    [-1, 2]             106\n",
            "================================================================\n",
            "Total params: 559,518\n",
            "Trainable params: 559,518\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.37\n",
            "Forward/backward pass size (MB): 1.34\n",
            "Params size (MB): 2.13\n",
            "Estimated Total Size (MB): 3.84\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs: 100%|██████████| 13/13 [00:37<00:00,  2.90s/it]\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "# Retrieve the best parameters\n",
        "best_params = study.best_params\n",
        "# example\n",
        "# best_params = {'learning_rate': 0.00012181579730390829, 'batch_size': 128, 'n_layers': 1, 'n_units': 128,\n",
        "            # 'dropout_prob': 0.48435216549373367, 'activation': 'PReLU', 'weight_init_method': 'normal', 'optimizer': 'SGD',\n",
        "            # 'use_early_stopping': False, 'patience': 8, 'epochs': 12, 'cnn_kernel': 3, 'cnn_stride': 2, 'cnn_padding': 3,\n",
        "            # 'cnn_channel': 32}\n",
        "\n",
        "\n",
        "# Wrap activation functions inside nn.Module subclass\n",
        "if best_params['activation'] == \"ReLU\":\n",
        "    activation =nn.ReLU()\n",
        "elif best_params['activation'] == \"LeakyReLU\":\n",
        "    activation =nn.LeakyReLU()\n",
        "elif best_params['activation'] == \"PReLU\":\n",
        "    activation =nn.PReLU()\n",
        "\n",
        "cnn_kernel = 2 * best_params['cnn_kernel'] + 1\n",
        "\n",
        "# Create an instance of your Network\n",
        "network2 = ConvolutionalNeuralNetwork2(input_dim = max_inp_len, d = d, output_dim=2, n_layers=best_params['n_layers'],\n",
        "                        n_units=best_params['n_units'], dropout_prob=best_params['dropout_prob'], activation=activation,\n",
        "                        optimizer_name=best_params['optimizer'],weight_init_method=best_params['weight_init_method'],\n",
        "                        learning_rate = best_params['learning_rate'],cnn_kernel = cnn_kernel,\n",
        "                        cnn_stride = best_params['cnn_stride'], cnn_padding = best_params['cnn_padding'],\n",
        "                        cnn_channel = best_params['cnn_channel'])\n",
        "\n",
        "optimizer = network2.optimizer\n",
        "epochs = best_params['epochs']\n",
        "hyp_accuracy=study.best_value\n",
        "cond=True\n",
        "\n",
        "# if hyp_accuracy < prev_eval_acc:\n",
        "#     cond=False\n",
        "#     network2=ConvolutionalNeuralNetwork0(d , num_classes=2)\n",
        "#     best_params['use_early_stopping'] = False\n",
        "#     epochs=10\n",
        "#     optimizer = torch.optim.Adam(network.parameters(), lr = 0.001)\n",
        "# # Learning rate scheduler\n",
        "# if lr_schedule == \"step_lr\":\n",
        "#     scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "# elif lr_schedule == \"exp_lr\":\n",
        "#     scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "network2 = network2.to(device)\n",
        "input_size = (100, 970)  # (channels, width)\n",
        "\n",
        "# Print the model summary\n",
        "summary(network2, input_size=input_size)\n",
        "\n",
        "\n",
        "best_eval_loss = float('inf')\n",
        "no_improvement = 0\n",
        "batch_size = best_params['batch_size']\n",
        "\n",
        "# Define DataLoader instances\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "eval_dataloader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False)\n",
        "# test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Training loop\n",
        "now_eval_acc = 0\n",
        "for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
        "    train_loss , train_acc = train_model(network2, criterion, optimizer, train_dataloader, device)\n",
        "    eval_loss, eval_acc = evaluate_model(network2, criterion, eval_dataloader, device)\n",
        "\n",
        "    train_epoch_loss.append(train_loss)\n",
        "    eval_epoch_loss.append(eval_loss)\n",
        "    now_eval_acc = eval_acc\n",
        "    # Early stopping\n",
        "    if best_params['use_early_stopping']:\n",
        "        if eval_loss < best_eval_loss:\n",
        "            best_val_loss = eval_loss\n",
        "            no_improvement = 0\n",
        "        else:\n",
        "            no_improvement += 1\n",
        "            if no_improvement >= best_params['patience']:\n",
        "                break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "2NHAGutAmDMS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "4161fcb6-e69c-4ab8-f395-2196f73630ef"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(epochs), train_epoch_loss, label='train')\n",
        "plt.plot(range(epochs), eval_epoch_loss, label='eval')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "k2ue7pgiWNRi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cf5ff30-51ae-4f8f-f489-fda4941a6152"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "# save model\n",
        "filename = \"Cnn_model.pickle\"\n",
        "\n",
        "if prev_eval_acc > now_eval_acc:\n",
        "  print(\"1\")\n",
        "  # pickle.dump(prev_model, open(filename, \"wb\"))\n",
        "  torch.save(prev_model.state_dict(), 'Cnn_model.pth')\n",
        "else:\n",
        "  # pickle.dump(network2, open(filename, \"wb\"))\n",
        "  torch.save(network2.state_dict(), 'Cnn_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = evaluate_model(network2, criterion, eval_dataloader, device)\n",
        "print(f\"Accuracy on Eval Data {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BM_KToHeMmTx",
        "outputId": "a219d44d-ea4c-49d0-a693-dc7f67ffc4e4"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Eval Data 0.7226415094339622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "torch.save(network2.state_dict(), 'Cnn_model.pth')\n",
        "# Assuming best_params is defined\n",
        "with open('Cnn_best_params.json', 'w') as f:\n",
        "    json.dump(best_params, f)"
      ],
      "metadata": {
        "id": "JHIBKcLJ7Dt6"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# network2.load_state_dict(torch.load('Cnn_model.pth', map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "id": "7qynOfxh5GyI"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv('test_split.csv')\n",
        "test_labels = test_data['label']\n",
        "test_embedding_matrix = create_embedding_matrix(test_data['tweet'], fasttext_model, max_inp_len)\n",
        "test_dataset = CustomDataset(test_embedding_matrix, test_labels)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = 32, shuffle = False)"
      ],
      "metadata": {
        "id": "cq_v_DcI4u-z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10a1a66f-2857-4f9e-d162-1df5d20f26eb"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1060, 970, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "JR1liwYjVF73"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_classification_report(model, test_dataloader, device, model_file = \"Cnn\"):\n",
        "    model.eval().to(device)\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "        for test_x, test_y in test_dataloader:\n",
        "            test_x, test_y = test_x.to(device), test_y.to(device)\n",
        "\n",
        "            if model_file == \"Cnn\":\n",
        "                outputs = model(test_x.permute(0,2,1))\n",
        "            else:\n",
        "                outputs = model(test_x)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            y_true.extend(test_y.cpu().numpy())\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f\"{model_file} Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Calculate and print precision, recall, and f1-score\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"{model_file} Precision: {precision:.4f}\")\n",
        "    print(f\"{model_file} Recall: {recall:.4f}\")\n",
        "    print(f\"{model_file} F1-Score: {f1:.4f}\")\n",
        "\n",
        "    # Print the classification report\n",
        "    print(f\"{model_file} Classification Report:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "XxqxjBtOVMAo"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('best_params.json', 'r') as f:\n",
        "    best_params = json.load(f)"
      ],
      "metadata": {
        "id": "dvlqjPxAX4MF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = ConvolutionalNeuralNetwork0(d)\n",
        "best_model2 = ConvolutionalNeuralNetwork2(input_dim = max_inp_len, d = d, output_dim=2, n_layers=best_params['n_layers'],\n",
        "                        n_units=best_params['n_units'], dropout_prob=best_params['dropout_prob'], activation=activation,\n",
        "                        optimizer_name=best_params['optimizer'],weight_init_method=best_params['weight_init_method'],\n",
        "                        learning_rate = best_params['learning_rate'],cnn_kernel = cnn_kernel,\n",
        "                        cnn_stride = best_params['cnn_stride'], cnn_padding = best_params['cnn_padding'],\n",
        "                        cnn_channel = best_params['cnn_channel'])\n",
        "try:\n",
        "    best_model.load_state_dict(torch.load('Cnn_model.pth', map_location=torch.device(device)))\n",
        "    get_classification_report(best_model, test_dataloader, device,\"Cnn\")\n",
        "except:\n",
        "    best_model2.load_state_dict(torch.load('Cnn_model.pth', map_location=torch.device(device)))\n",
        "    report = get_classification_report(best_model2, test_dataloader, device,\"Cnn\")\n",
        "    best_model = best_model2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPZiCQ1MRc4x",
        "outputId": "217935c0-d6b6-45c0-e6a8-e30c7d26db99"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cnn Accuracy: 0.9132\n",
            "Cnn Precision: 0.9181\n",
            "Cnn Recall: 0.9132\n",
            "Cnn F1-Score: 0.9133\n",
            "Cnn Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91       496\n",
            "           1       0.96      0.87      0.91       564\n",
            "\n",
            "    accuracy                           0.91      1060\n",
            "   macro avg       0.92      0.92      0.91      1060\n",
            "weighted avg       0.92      0.91      0.91      1060\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYrBjHhZHzKF"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 4515722,
          "sourceId": 7731342,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30664,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}