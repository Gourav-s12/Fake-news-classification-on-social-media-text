# -*- coding: utf-8 -*-
"""Lstm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hLsNH1XN6qOGuNydNErwmJ1uXDn2VRgg
"""

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC,LinearSVC
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import pickle
# import torch
# import torch.nn as nn
# from torch.utils.data import Dataset
# from torch.utils.data import DataLoader
from tqdm import tqdm
# ! pip install optuna
import optuna
# !pip install fasttext
import fasttext

# !pip install torch torchvision torchaudio
# !pip install --upgrade torch torchvision torchaudio

import torch
import torch.nn as nn
from torch.utils.data import Dataset
from torch.utils.data import DataLoader

"""# task 1 , 2 , 3 (load)"""

train_data = pd.read_csv('train_split.csv')
val_data = pd.read_csv('val_split.csv')
# test_data = pd.read_csv('test_split.csv')

train_labels = train_data['label']
val_labels = val_data['label']
# test_labels = test_data['label']

# Combine train and validation data for fasttext training
combined_data = pd.concat([train_data, val_data])

# Combine train and validation sentences for fasttext training
combined_data_df = pd.concat([train_data, val_data], axis=0)
max_inp_len = max(combined_data_df['tweet'].apply(lambda x: len(x.split(" "))))

combined_data_df[["tweet"]].to_csv('combined_data.txt', header=False, index=False,  encoding='utf-8')

# Specify the path for the fasttext model
fasttext_model_path = 'fasttext_model.bin'

# Train the FastText model on the combined dataset
model = fasttext.train_unsupervised('combined_data.txt', model='skipgram')
model.save_model(fasttext_model_path)

# Specify the path for the fasttext model
fasttext_model_path = 'fasttext_model.bin'

fasttext_model = fasttext.load_model(fasttext_model_path)

import numpy as np

def create_embedding_matrix(sentences, model, max_inp_len):
    embedding_matrix = np.zeros((len(sentences), max_inp_len, model.get_dimension()))

    for i, sentence in enumerate(sentences):
        tokens = sentence.split()[:max_inp_len]
        for j, token in enumerate(tokens):
            embedding_matrix[i, j, :] = model.get_word_vector(token)

    print(embedding_matrix.shape)
    return embedding_matrix

max_inp_len = max(pd.concat([train_data, val_data], axis=0)['tweet'].apply(lambda x: len(x.split(" "))))
d = fasttext_model.get_dimension()
print(max_inp_len , d)

# Create embedding matrices for train, val, and test datasets
train_embedding_matrix = create_embedding_matrix(train_data['tweet'], fasttext_model, max_inp_len)
val_embedding_matrix = create_embedding_matrix(val_data['tweet'], fasttext_model, max_inp_len)
# test_embedding_matrix = create_embedding_matrix(test_data['tweet'], fasttext_model, max_inp_len)

train_labels.shape , train_embedding_matrix.shape

val_labels.shape , val_embedding_matrix.shape

"""# Task 4"""

class CustomDataset(Dataset):
    def __init__(self, X, Y):
        # Convert sparse matrix to dense tensor
        self.x = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(Y, dtype=torch.long)

    def __len__(self):
        return len(self.y)

    def __getitem__(self, idx):
        # Add an extra dimension to represent channels (1 in this case)
        x_sample = self.x[idx]   # .unsqueeze(0)
        return x_sample, self.y[idx]

train_dataset = CustomDataset(train_embedding_matrix, train_labels)
eval_dataset = CustomDataset(val_embedding_matrix, val_labels)
# test_dataset = CustomDataset(test_embedding_matrix, test_labels)

train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle = True)
eval_dataloader = DataLoader(eval_dataset, batch_size = 32, shuffle = False)
# test_dataloader = DataLoader(test_dataset, batch_size = 32, shuffle = False)

for x, y in train_dataloader:
    print(x.shape, y.shape)
    break

# train_loader = torch.utils.data.DataLoader(train_dataset,          # our raw data
#                                            batch_size=32,  # the size of batches we want the dataloader to return
#                                            shuffle=True,           # shuffle our data before batching
#                                            drop_last=False)        # don't drop the last batch even if it's smaller than batch_size
# imgs, targets = next(iter(train_loader))
# imgs.shape

"""## Basic Network"""

device = "cuda" if torch.cuda.is_available() else "cpu"
print(device)

import torch.nn as nn

class LSTM0(nn.Module):
    def __init__(self, input_size, num_layers= 1, output_size =2):
        super(LSTM0, self).__init__()

        self.lstm = nn.LSTM(input_size, 256, num_layers, batch_first=True, bidirectional=True)
        self.fc = nn.Linear(256 * 2, output_size)  # multiplied by 2 for bidirectional LSTM

    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        lstm_out = lstm_out[:, -1, :]  # Take the output from the last time step
        x = self.fc(lstm_out)
        return x

import torch
network = LSTM0(input_size=d).to(device)

from torchsummary import summary
# Assuming your input data size is (970, 100)
# input_size = (100 ,) # (channels, width)

# # Print the model summary
# summary(network, input_size=d)

batch_x, batch_y = next(iter(train_dataloader))
print(batch_x.shape, batch_y.shape)

"""## Basic Training Loop"""

criterion = nn.CrossEntropyLoss()
optim = torch.optim.Adam(network.parameters(), lr = 0.001)
epochs = 10

train_epoch_loss = []
eval_epoch_loss = []

for epoch in tqdm(range(epochs)):
    curr_loss = 0
    total = 0
    for train_x, train_y in train_dataloader:

        train_x = train_x.to(device)
        train_y = train_y.to(device)
        optim.zero_grad()

        y_pred = network(train_x)
        loss = criterion(y_pred, train_y)

        loss.backward()
        optim.step()

        curr_loss += loss.item()
        total += len(train_y)
    train_epoch_loss.append(curr_loss / total)

    curr_loss = 0
    total = 0
    for eval_x, eval_y in eval_dataloader:
        eval_x = eval_x.to(device)
        eval_y = eval_y.to(device)
        optim.zero_grad()

        with torch.no_grad():
            y_pred = network(eval_x)

        loss = criterion(y_pred, eval_y)

        curr_loss += loss.item()
        total += len(train_y)
    eval_epoch_loss.append(curr_loss / total)

# import matplotlib.pyplot as plt

# plt.plot(range(epochs), train_epoch_loss, label='train')
# plt.plot(range(epochs), eval_epoch_loss, label='eval')
# plt.xlabel('Epoch')
# plt.ylabel('Loss')
# plt.legend()
# plt.show()

correct = 0
total = 0
for x, y in eval_dataloader:
    x = x.to(device)
    with torch.no_grad():
        yp = network(x)
    yp = torch.argmax(yp.cpu(), dim = 1)
    correct += (yp == y).sum()
    total += len(y)
prev_eval_acc = correct / total
print(f"Accuracy on Eval Data {(prev_eval_acc * 100):.2f}")

prev_model = network

# save model
torch.save(prev_model.state_dict(), 'lstm_model_p.pth')

"""## now hyperparameter optimization"""

# !pip install torchmetrics
from torchmetrics import Accuracy

class LSTM2(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim =2, num_layers=1, dropout=0.2, bidirectional=False):
        super(LSTM2, self).__init__()
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.output_dim = output_dim
        self.num_layers = num_layers
        self.dropout = dropout
        self.bidirectional = bidirectional

        # LSTM layer
        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True, dropout=dropout, bidirectional=bidirectional)

        # Fully connected layer
        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)

    def forward(self, x):
        # x: [batch_size, seq_length, input_dim]

        # LSTM
        lstm_out, _ = self.lstm(x)

        # Extract the output of the last time step
        last_output = lstm_out[:, -1, :]

        # Fully connected layer
        out = self.fc(last_output)

        return out

def train_model(model, criterion, optimizer, dataloader, device):
    model.train()
    total_loss = 0.0
    correct_predictions = 0
    total_samples = 0

    for inputs, targets in dataloader:
        inputs, targets = inputs.to(device), targets.to(device)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, targets)

        # Calculate accuracy
        y_pred = torch.argmax(outputs, dim = 1)
        correct_predictions += (y_pred == targets).sum().item()
        total_samples += len(targets)

        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    accuracy = correct_predictions / total_samples
    total_loss /= total_samples
    return total_loss, accuracy

def evaluate_model(network, criterion, eval_dataloader, device):
    network.eval()

    total_loss = 0
    correct_predictions = 0
    total_samples = 0

    with torch.no_grad():
        for eval_x, eval_y in eval_dataloader:
            eval_x = eval_x.to(device)
            eval_y = eval_y.to(device)

            y_pred = network(eval_x)
            loss = criterion(y_pred, eval_y)

            total_loss += loss.item()

            # Calculate accuracy
            y_pred = torch.argmax(y_pred, dim = 1)
            correct_predictions += (y_pred == eval_y).sum().item()
            total_samples += len(eval_y)

    total_loss /= total_samples
    accuracy = correct_predictions / total_samples

    return total_loss, accuracy

import optuna
from torch.optim.lr_scheduler import StepLR, ExponentialLR
from torch.nn.init import xavier_uniform_, kaiming_normal_
from torch.optim import Adam, SGD
from torch.optim.lr_scheduler import StepLR, ExponentialLR
from torch.nn import LeakyReLU, PReLU
from torch.utils.data import DataLoader
from torch.nn import L1Loss, MSELoss

def objective(trial):
    # Define hyperparameters to be optimized

    hidden_dim = trial.suggest_int('hidden_dim', 64, 256)
    num_layers = trial.suggest_int('num_layers', 1, 3)
    dropout = trial.suggest_float('dropout', 0.0, 0.4)
    bidirectional = trial.suggest_categorical('bidirectional', [True, False])
    activation = trial.suggest_categorical("activation", ["ReLU", "LeakyReLU", "PReLU"])
    epochs = trial.suggest_int("epochs", 10, 20)

    # Instantiate the model with the sampled hyperparameters
    network = LSTM2(d, hidden_dim, 2, num_layers, dropout, bidirectional)

    optimizer = torch.optim.Adam(network.parameters(), lr = 0.001)

    # input_size = (100, 970)  # (channels, width)

    # # Print the model summary
    # summary(network, input_size=input_size)

    # Move the model to the appropriate device
    network.to(device)
    best_eval_loss = float('inf')
    no_improvement = 0
    batch_size =32

    # Define DataLoader instances
    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    eval_dataloader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False)
    # test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    # Training loop
    for epoch in tqdm(range(epochs), desc="Epochs"):
        train_loss , train_acc = train_model(network, criterion, optimizer, train_dataloader, device)
        eval_loss, eval_acc = evaluate_model(network, criterion, eval_dataloader, device)

        # Report the validation loss to Optuna for optimization
        trial.report(eval_loss, epoch)

        # Handle pruning based on the intermediate value
        if trial.should_prune():
            raise optuna.exceptions.TrialPruned()

    print(f"Training acc = {train_acc} , Val acc = {eval_acc}")
    return eval_acc  # eval_loss

# Create Optuna study and run optimization
study = optuna.create_study(direction="maximize")  # or "minimize" for a loss
study.optimize(objective, n_trials=10, timeout=5000)

print("Best trial:")
trial = study.best_trial
print("  Value: ", trial.value)

print("  Params: ")
for key, value in trial.params.items():
    print("    {}: {}".format(key, value))

train_epoch_loss = []
eval_epoch_loss = []

from torchsummary import summary
# Retrieve the best parameters
best_params = study.best_params
# example
# best_params = {'learning_rate': 0.007328217711618778, 'batch_size': 32, 'n_layers': 2, 'n_units': 64,
#                'dropout_prob': 0.0758288355159868, 'activation': 'PReLU', 'weight_init_method': 'xavier',
#                'optimizer': 'RMSprop', 'use_early_stopping': False, 'patience': 8, 'epochs': 19, 'cnn_kernel': 3,
#                'cnn_stride': 3, 'cnn_padding': 0, 'cnn_channel': 128}


# Create an instance of your Network
network2 = LSTM2(d, hidden_dim=best_params['hidden_dim'], output_dim =2, num_layers=best_params['num_layers'], dropout=best_params['dropout'], bidirectional=best_params['bidirectional'])

network2.to(device)
optimizer = torch.optim.Adam(network2.parameters(), lr = 0.001)

# # Learning rate scheduler
# if lr_schedule == "step_lr":
#     scheduler = StepLR(optimizer, step_size=5, gamma=0.1)
# elif lr_schedule == "exp_lr":
#     scheduler = ExponentialLR(optimizer, gamma=0.9)

# Move the model to the appropriate device
# input_size = (100, 970)  # (channels, width)

# # Print the model summary
# summary(network2, input_size=input_size)


best_eval_loss = float('inf')
no_improvement = 0
batch_size = 32
epochs = best_params['epochs']

# Define DataLoader instances
train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
eval_dataloader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False)
# test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# Training loop
now_eval_acc = 0
for epoch in tqdm(range(epochs), desc="Epochs"):
    train_loss , train_acc = train_model(network2, criterion, optimizer, train_dataloader, device)
    eval_loss, eval_acc = evaluate_model(network2, criterion, eval_dataloader, device)

    train_epoch_loss.append(train_loss)
    eval_epoch_loss.append(eval_loss)
    now_eval_acc = eval_acc

# import matplotlib.pyplot as plt

# plt.plot(range(epochs), train_epoch_loss, label='train')
# plt.plot(range(epochs), eval_epoch_loss, label='eval')
# plt.xlabel('Epoch')
# plt.ylabel('Loss')
# plt.legend()
# plt.show()

test_loss, test_acc = evaluate_model(network2, criterion, eval_dataloader, device)
print(f"Accuracy on Eval Data {test_acc}")

# save model
filename = "lstm_model.pickle"

if prev_eval_acc > now_eval_acc:
  print("1")
  # pickle.dump(prev_model, open(filename, "wb"))
  torch.save(prev_model.state_dict(), 'Lstm_model.pth')
else:
  # pickle.dump(network2, open(filename, "wb"))
  torch.save(network2.state_dict(), 'Lstm_model.pth')

import json

# torch.save(network2.state_dict(), 'Dnn_model.pth')
# Assuming best_params is defined
with open('Lstm_best_params.json', 'w') as f:
    json.dump(best_params, f)

# testing on test data 
# test_data = pd.read_csv('test_split.csv')
# test_labels = test_data['label']
# test_embedding_matrix = create_embedding_matrix(test_data['tweet'], fasttext_model, max_inp_len)
# test_dataset = CustomDataset(test_embedding_matrix, test_labels)
# test_dataloader = DataLoader(test_dataset, batch_size = 32, shuffle = False)

# from sklearn.metrics import accuracy_score, classification_report

# def get_classification_report(model, test_dataloader, device, model_file = "Cnn"):
#     model.eval().to(device)
#     y_true = []
#     y_pred = []
#     with torch.no_grad():
#         for test_x, test_y in test_dataloader:
#             test_x, test_y = test_x.to(device), test_y.to(device)

#             if model_file == "Cnn":
#                 outputs = model(test_x.permute(0,2,1))
#             else:
#                 outputs = model(test_x)
#             _, predicted = torch.max(outputs.data, 1)
#             y_true.extend(test_y.cpu().numpy())
#             y_pred.extend(predicted.cpu().numpy())

#     accuracy = accuracy_score(y_true, y_pred)
#     print(f"{model_file} Accuracy: {accuracy:.4f}")

#     # Calculate and print precision, recall, and f1-score
#     precision = precision_score(y_true, y_pred, average='weighted')
#     recall = recall_score(y_true, y_pred, average='weighted')
#     f1 = f1_score(y_true, y_pred, average='weighted')

#     print(f"{model_file} Precision: {precision:.4f}")
#     print(f"{model_file} Recall: {recall:.4f}")
#     print(f"{model_file} F1-Score: {f1:.4f}")

#     # Print the classification report
#     print(f"{model_file} Classification Report:")
#     print(classification_report(y_true, y_pred))
#     print("\n")

# with open('Lstm_best_params.json', 'r') as f:
#     best_params = json.load(f)

# best_model = LSTM0(input_size=d)
# best_model2 = LSTM2(d, hidden_dim=best_params['hidden_dim'], output_dim =2, num_layers=best_params['num_layers'], dropout=best_params['dropout'], bidirectional=best_params['bidirectional'])
# try:
#     best_model.load_state_dict(torch.load('Lstm_model.pth', map_location=torch.device(device)))
#     get_classification_report(best_model, test_dataloader, device,"Lstm")
# except:
#     best_model2.load_state_dict(torch.load('Lstm_model.pth', map_location=torch.device(device)))
#     report = get_classification_report(best_model2, test_dataloader, device,"Lstm")
#     best_model = best_model2